{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "from sklearn import svm\n",
    "import gensim.models as g\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/daviddeng8/Documents/Projects/affinity/data/preprocessed_cleaned_body.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Bias</th>\n",
       "      <th>cleaned_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abortion rights advocates have asked the U.S. ...</td>\n",
       "      <td>1.67</td>\n",
       "      <td>abortion right advocate asked u supreme court ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A federal appeals court rejected the most dire...</td>\n",
       "      <td>0.67</td>\n",
       "      <td>federal appeal court rejected direct constitut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As part of the Trump administration's effort t...</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>part trump administration effort slow migrant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>President Donald Trump and \"the Trump of the T...</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>president donald trump trump tropic brazilian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.S Senator Elizabeth Warren, who is competing...</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>u senator elizabeth warren competing democrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>Only hours after the first flames that eventua...</td>\n",
       "      <td>19.75</td>\n",
       "      <td>hour first flame eventually would consume notr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>Washington watchdog Judicial Watch believes th...</td>\n",
       "      <td>30.50</td>\n",
       "      <td>washington watchdog judicial watch belief fbi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>Two Fox News personalities, as Notre Dame Cath...</td>\n",
       "      <td>29.75</td>\n",
       "      <td>two fox news personality notre dame cathedral ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>Chase Bank is shutting down accounts of people...</td>\n",
       "      <td>22.00</td>\n",
       "      <td>chase bank shutting account people organizatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>Rep. Adam Schiff, D-Calif., unwilling to give ...</td>\n",
       "      <td>26.00</td>\n",
       "      <td>rep adam schiff dcalif unwilling give claim do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1675 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Body   Bias  \\\n",
       "0     Abortion rights advocates have asked the U.S. ...   1.67   \n",
       "1     A federal appeals court rejected the most dire...   0.67   \n",
       "2     As part of the Trump administration's effort t...  -2.75   \n",
       "3     President Donald Trump and \"the Trump of the T...  -4.33   \n",
       "4     U.S Senator Elizabeth Warren, who is competing... -10.00   \n",
       "...                                                 ...    ...   \n",
       "1670  Only hours after the first flames that eventua...  19.75   \n",
       "1671  Washington watchdog Judicial Watch believes th...  30.50   \n",
       "1672  Two Fox News personalities, as Notre Dame Cath...  29.75   \n",
       "1673  Chase Bank is shutting down accounts of people...  22.00   \n",
       "1674  Rep. Adam Schiff, D-Calif., unwilling to give ...  26.00   \n",
       "\n",
       "                                           cleaned_body  \n",
       "0     abortion right advocate asked u supreme court ...  \n",
       "1     federal appeal court rejected direct constitut...  \n",
       "2     part trump administration effort slow migrant ...  \n",
       "3     president donald trump trump tropic brazilian ...  \n",
       "4     u senator elizabeth warren competing democrati...  \n",
       "...                                                 ...  \n",
       "1670  hour first flame eventually would consume notr...  \n",
       "1671  washington watchdog judicial watch belief fbi ...  \n",
       "1672  two fox news personality notre dame cathedral ...  \n",
       "1673  chase bank shutting account people organizatio...  \n",
       "1674  rep adam schiff dcalif unwilling give claim do...  \n",
       "\n",
       "[1675 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra preprocessing of data\n",
    "\n",
    "wordsToCut = set(stopwords.words('english'))\n",
    "\n",
    "def getPOS(words):\n",
    "    #return nltk.pos_tag(word)\n",
    "    return [(word, get_wordnet_pos(word)) for word in words]\n",
    "\n",
    "def getIndividualPOS(word):\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV} \n",
    "    tag = nltk.pos_tag(word[0].upper())\n",
    "    return tag_dict.get(tag)\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}    \n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    #removing stopwords and punctuation\n",
    "    tokenized = nltk.word_tokenize(row['Body'])\n",
    "    temp = [word for word in tokenized if word.lower() not in wordsToCut and word not in string.punctuation and word.isalpha()]\n",
    "    \n",
    "    #row['Body'] = ' '.join(temp)\n",
    "    \n",
    "    #row['Body'] = [word for word in nltk.word_tokenize(row['Body']) if word not in wordsToCut]\n",
    "    #row['Body'] = row['Body'].lower()\n",
    "    #nopunc = [char for char in row['Body'] if char not in string.punctuation]\n",
    "    #nopunc.join('')\n",
    "    \n",
    "    #lemmatizing, ONLY KEEPING ENTITIES\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    partsOfSpeech = getPOS(temp)\n",
    "    \n",
    "    lemmatized = [lemmatizer.lemmatize(word, pos) for word, pos in partsOfSpeech if pos == 'n']\n",
    "    final = ' '.join(lemmatized)\n",
    "    df.at[index, 'Body'] = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daviddeng8/anaconda2/envs/practice/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/daviddeng8/anaconda2/envs/practice/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Bias</th>\n",
       "      <th>cleaned_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abortion right advocate Supreme Court strike L...</td>\n",
       "      <td>1</td>\n",
       "      <td>abortion right advocate asked u supreme court ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>appeal court challenge counsel Robert Mueller ...</td>\n",
       "      <td>1</td>\n",
       "      <td>federal appeal court rejected direct constitut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Michael Cohen New York per decision Department...</td>\n",
       "      <td>1</td>\n",
       "      <td>michael cohen ha officially disbarred new york...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>President Donald Trump vetoed resolution stop ...</td>\n",
       "      <td>1</td>\n",
       "      <td>president donald trump ha vetoed resolution st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>body camera footage reveals police man authori...</td>\n",
       "      <td>1</td>\n",
       "      <td>newlyreleased body camera footage reveals dram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>DAY BIGGEST NIGH Thursday release whatever bul...</td>\n",
       "      <td>0</td>\n",
       "      <td>day biggest coverup nigh thursday anticipating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>man lady letter internet tradition online web ...</td>\n",
       "      <td>0</td>\n",
       "      <td>man lady letter also versed internet tradition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>Attorney General William Barr would like remin...</td>\n",
       "      <td>0</td>\n",
       "      <td>attorney general william barr would like remin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>PASTEMAGAZINE Monday night Bernie Sanders town...</td>\n",
       "      <td>0</td>\n",
       "      <td>pastemagazine — monday night bernie sander tow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>Princeton University economist Alan Krueger to...</td>\n",
       "      <td>0</td>\n",
       "      <td>princeton university economist alan krueger se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1675 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Body  Bias  \\\n",
       "0     Abortion right advocate Supreme Court strike L...     1   \n",
       "1     appeal court challenge counsel Robert Mueller ...     1   \n",
       "7     Michael Cohen New York per decision Department...     1   \n",
       "13    President Donald Trump vetoed resolution stop ...     1   \n",
       "15    body camera footage reveals police man authori...     1   \n",
       "...                                                 ...   ...   \n",
       "1657  DAY BIGGEST NIGH Thursday release whatever bul...     0   \n",
       "1658  man lady letter internet tradition online web ...     0   \n",
       "1659  Attorney General William Barr would like remin...     0   \n",
       "1661  PASTEMAGAZINE Monday night Bernie Sanders town...     0   \n",
       "1668  Princeton University economist Alan Krueger to...     0   \n",
       "\n",
       "                                           cleaned_body  \n",
       "0     abortion right advocate asked u supreme court ...  \n",
       "1     federal appeal court rejected direct constitut...  \n",
       "7     michael cohen ha officially disbarred new york...  \n",
       "13    president donald trump ha vetoed resolution st...  \n",
       "15    newlyreleased body camera footage reveals dram...  \n",
       "...                                                 ...  \n",
       "1657  day biggest coverup nigh thursday anticipating...  \n",
       "1658  man lady letter also versed internet tradition...  \n",
       "1659  attorney general william barr would like remin...  \n",
       "1661  pastemagazine — monday night bernie sander tow...  \n",
       "1668  princeton university economist alan krueger se...  \n",
       "\n",
       "[1675 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right = df.loc[df['Bias'] > 0]\n",
    "left = df.loc[df['Bias'] <= 0]\n",
    "\n",
    "# 1 = Right bias, 0 = Left bias\n",
    "right['Bias'] = 1\n",
    "left['Bias'] = 0\n",
    "\n",
    "cat_df = pd.concat([right, left])\n",
    "cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cat_df.iloc[:, cat_df.columns != 'Bias']\n",
    "Y = cat_df['Bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>cleaned_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abortion right advocate Supreme Court strike L...</td>\n",
       "      <td>abortion right advocate asked u supreme court ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>appeal court challenge counsel Robert Mueller ...</td>\n",
       "      <td>federal appeal court rejected direct constitut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Michael Cohen New York per decision Department...</td>\n",
       "      <td>michael cohen ha officially disbarred new york...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>President Donald Trump vetoed resolution stop ...</td>\n",
       "      <td>president donald trump ha vetoed resolution st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>body camera footage reveals police man authori...</td>\n",
       "      <td>newlyreleased body camera footage reveals dram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>DAY BIGGEST NIGH Thursday release whatever bul...</td>\n",
       "      <td>day biggest coverup nigh thursday anticipating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>man lady letter internet tradition online web ...</td>\n",
       "      <td>man lady letter also versed internet tradition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>Attorney General William Barr would like remin...</td>\n",
       "      <td>attorney general william barr would like remin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>PASTEMAGAZINE Monday night Bernie Sanders town...</td>\n",
       "      <td>pastemagazine — monday night bernie sander tow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>Princeton University economist Alan Krueger to...</td>\n",
       "      <td>princeton university economist alan krueger se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1675 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Body  \\\n",
       "0     Abortion right advocate Supreme Court strike L...   \n",
       "1     appeal court challenge counsel Robert Mueller ...   \n",
       "7     Michael Cohen New York per decision Department...   \n",
       "13    President Donald Trump vetoed resolution stop ...   \n",
       "15    body camera footage reveals police man authori...   \n",
       "...                                                 ...   \n",
       "1657  DAY BIGGEST NIGH Thursday release whatever bul...   \n",
       "1658  man lady letter internet tradition online web ...   \n",
       "1659  Attorney General William Barr would like remin...   \n",
       "1661  PASTEMAGAZINE Monday night Bernie Sanders town...   \n",
       "1668  Princeton University economist Alan Krueger to...   \n",
       "\n",
       "                                           cleaned_body  \n",
       "0     abortion right advocate asked u supreme court ...  \n",
       "1     federal appeal court rejected direct constitut...  \n",
       "7     michael cohen ha officially disbarred new york...  \n",
       "13    president donald trump ha vetoed resolution st...  \n",
       "15    newlyreleased body camera footage reveals dram...  \n",
       "...                                                 ...  \n",
       "1657  day biggest coverup nigh thursday anticipating...  \n",
       "1658  man lady letter also versed internet tradition...  \n",
       "1659  attorney general william barr would like remin...  \n",
       "1661  pastemagazine — monday night bernie sander tow...  \n",
       "1668  princeton university economist alan krueger se...  \n",
       "\n",
       "[1675 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "7       1\n",
       "13      1\n",
       "15      1\n",
       "       ..\n",
       "1657    0\n",
       "1658    0\n",
       "1659    0\n",
       "1661    0\n",
       "1668    0\n",
       "Name: Bias, Length: 1675, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abuse</th>\n",
       "      <th>access</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>accused</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>would</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>year</th>\n",
       "      <th>yearold</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>zealand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1675 rows × 800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ability  able  abortion  abuse  access  according  account  accused  \\\n",
       "0           0     0        11      0       2          0        0        0   \n",
       "1           0     0         0      0       0          0        0        0   \n",
       "2           0     0         0      0       0          0        0        0   \n",
       "3           0     0         0      0       0          0        0        0   \n",
       "4           0     0         0      0       0          0        0        0   \n",
       "...       ...   ...       ...    ...     ...        ...      ...      ...   \n",
       "1670        0     0         0      0       0          0        0        0   \n",
       "1671        0     0         0      0       0          0        0        0   \n",
       "1672        0     0         0      1       0          0        0        0   \n",
       "1673        0     1         0      0       0          0        0        0   \n",
       "1674        0     0         0      0       0          1        0        0   \n",
       "\n",
       "      across  act  ...  would  wrong  wrote  year  yearold  yet  york  you  \\\n",
       "0          1    0  ...      1      0      0     0        0    0     0    0   \n",
       "1          0    0  ...      0      0      2     0        0    0     0    0   \n",
       "2          0    0  ...      1      0      0     0        0    0     3    0   \n",
       "3          0    1  ...      0      0      0     3        0    0     0    0   \n",
       "4          0    0  ...      0      0      0     1        2    0     0    1   \n",
       "...      ...  ...  ...    ...    ...    ...   ...      ...  ...   ...  ...   \n",
       "1670       0    0  ...      3      0      0     0        0    0     0    0   \n",
       "1671       0    0  ...      3      1      0     0        0    0     0    0   \n",
       "1672       0    1  ...      4      0      1     2        0    0     1    0   \n",
       "1673       0    0  ...      2      0      0     0        0    0     0    0   \n",
       "1674       0    0  ...      0      0      1     2        0    0     0    0   \n",
       "\n",
       "      young  zealand  \n",
       "0         0        0  \n",
       "1         0        0  \n",
       "2         0        0  \n",
       "3         0        0  \n",
       "4         1        0  \n",
       "...     ...      ...  \n",
       "1670      0        0  \n",
       "1671      0        0  \n",
       "1672      0        0  \n",
       "1673      0        0  \n",
       "1674      0        0  \n",
       "\n",
       "[1675 rows x 800 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(max_features = 800)\n",
    "bow = bow_transformer.fit_transform(X['cleaned_body'])\n",
    "\n",
    "X = pd.DataFrame(bow.toarray(), columns=bow_transformer.get_feature_names())\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = X.columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(scaled, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abuse</th>\n",
       "      <th>access</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>accused</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>...</th>\n",
       "      <th>would</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>year</th>\n",
       "      <th>yearold</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>zealand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1675 rows × 800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ability  able  abortion     abuse  access  according  account  accused  \\\n",
       "0         0.0  0.00   0.52381  0.000000     0.2   0.000000      0.0      0.0   \n",
       "1         0.0  0.00   0.00000  0.000000     0.0   0.000000      0.0      0.0   \n",
       "2         0.0  0.00   0.00000  0.000000     0.0   0.000000      0.0      0.0   \n",
       "3         0.0  0.00   0.00000  0.000000     0.0   0.000000      0.0      0.0   \n",
       "4         0.0  0.00   0.00000  0.000000     0.0   0.000000      0.0      0.0   \n",
       "...       ...   ...       ...       ...     ...        ...      ...      ...   \n",
       "1670      0.0  0.00   0.00000  0.000000     0.0   0.000000      0.0      0.0   \n",
       "1671      0.0  0.00   0.00000  0.000000     0.0   0.000000      0.0      0.0   \n",
       "1672      0.0  0.00   0.00000  0.071429     0.0   0.000000      0.0      0.0   \n",
       "1673      0.0  0.25   0.00000  0.000000     0.0   0.000000      0.0      0.0   \n",
       "1674      0.0  0.00   0.00000  0.000000     0.0   0.041667      0.0      0.0   \n",
       "\n",
       "        across       act  ...     would     wrong     wrote      year  \\\n",
       "0     0.142857  0.000000  ...  0.018182  0.000000  0.000000  0.000000   \n",
       "1     0.000000  0.000000  ...  0.000000  0.000000  0.153846  0.000000   \n",
       "2     0.000000  0.000000  ...  0.018182  0.000000  0.000000  0.000000   \n",
       "3     0.000000  0.058824  ...  0.000000  0.000000  0.000000  0.076923   \n",
       "4     0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.025641   \n",
       "...        ...       ...  ...       ...       ...       ...       ...   \n",
       "1670  0.000000  0.000000  ...  0.054545  0.000000  0.000000  0.000000   \n",
       "1671  0.000000  0.000000  ...  0.054545  0.166667  0.000000  0.000000   \n",
       "1672  0.000000  0.058824  ...  0.072727  0.000000  0.076923  0.051282   \n",
       "1673  0.000000  0.000000  ...  0.036364  0.000000  0.000000  0.000000   \n",
       "1674  0.000000  0.000000  ...  0.000000  0.000000  0.076923  0.051282   \n",
       "\n",
       "      yearold  yet      york       you     young  zealand  \n",
       "0         0.0  0.0  0.000000  0.000000  0.000000      0.0  \n",
       "1         0.0  0.0  0.000000  0.000000  0.000000      0.0  \n",
       "2         0.0  0.0  0.130435  0.000000  0.000000      0.0  \n",
       "3         0.0  0.0  0.000000  0.000000  0.000000      0.0  \n",
       "4         0.4  0.0  0.000000  0.066667  0.111111      0.0  \n",
       "...       ...  ...       ...       ...       ...      ...  \n",
       "1670      0.0  0.0  0.000000  0.000000  0.000000      0.0  \n",
       "1671      0.0  0.0  0.000000  0.000000  0.000000      0.0  \n",
       "1672      0.0  0.0  0.043478  0.000000  0.000000      0.0  \n",
       "1673      0.0  0.0  0.000000  0.000000  0.000000      0.0  \n",
       "1674      0.0  0.0  0.000000  0.000000  0.000000      0.0  \n",
       "\n",
       "[1675 rows x 800 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.7136038186157518\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (\"accuracy score: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''vectorizer = TfidfVectorier(use_idf=True, stop_words='english')\n",
    "matrix = vectorizer.fit_transform()'''\n",
    "X_tfidf = cat_df['cleaned_body']\n",
    "Y_tfidf = cat_df['Bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf = True, stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = vectorizer.fit_transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(matrix.toarray(), columns=vectorizer.get_feature_names())\n",
    "#X = pd.DataFrame(bow.toarray(), columns=bow_transformer.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = df.columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(scaled, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(df, Y_tfidf, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC()\n",
    "print (\"hi\")\n",
    "model.fit(X_train2, y_train2)\n",
    "print (\"2\")\n",
    "y_pred = model.predict(X_test2)\n",
    "print (\"3\")\n",
    "print (\"accuracy score: \", accuracy_score(y_test2, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = cat_df['cleaned_body']\n",
    "new_df = cat_df.drop('Body', axis=1)\n",
    "#ls = [body.split() for body in text]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls = [body.split(), rating for body, rating in new_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newX_train, newX_test, newy_train, newy_test = train_test_split(X, Y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc.split(), [i]) for doc in cat_df['cleaned_body'] for i in cat_df['Bias']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.infer_vector(ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
