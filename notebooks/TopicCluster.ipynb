{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsToCut = set(stopwords.words('english'))\n",
    "wordsToCut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print ('A' in wordsToCut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Url</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Body</th>\n",
       "      <th>n_links</th>\n",
       "      <th>Source</th>\n",
       "      <th>Bias</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://abcnews.go.com/Politics/abortion-right...</td>\n",
       "      <td>Devin Dwyer</td>\n",
       "      <td>Wed, 17 Apr 2019 10:14:00 GMT</td>\n",
       "      <td>Abortion rights group asks Supreme Court to st...</td>\n",
       "      <td>Abortion rights advocates have asked the U.S. ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>1.67</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://abcnews.go.com/Politics/appeals-court-...</td>\n",
       "      <td>Ali Dukakis</td>\n",
       "      <td>Tue, 26 Feb 2019 09:05:00 GMT</td>\n",
       "      <td>Appeals court says special counsel Robert Muel...</td>\n",
       "      <td>A federal appeals court rejected the most dire...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>0.67</td>\n",
       "      <td>51.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://abcnews.go.com/Politics/attorney-gener...</td>\n",
       "      <td>Luke Barr</td>\n",
       "      <td>Wed, 17 Apr 2019 14:02:00 GMT</td>\n",
       "      <td>Attorney general orders some asylum seekers to...</td>\n",
       "      <td>As part of the Trump administration's effort t...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>43.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://abcnews.go.com/Politics/donald-trump-t...</td>\n",
       "      <td>Meridith McGraw</td>\n",
       "      <td>Tue, 19 Mar 2019 12:44:00 GMT</td>\n",
       "      <td>Donald Trump and 'the Trump of the Tropics,' B...</td>\n",
       "      <td>President Donald Trump and \"the Trump of the T...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>52.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://abcnews.go.com/Politics/electoral-coll...</td>\n",
       "      <td>Matthew Dowd</td>\n",
       "      <td>Tue, 19 Mar 2019 21:39:00 GMT</td>\n",
       "      <td>The Electoral College limits the campaign play...</td>\n",
       "      <td>U.S Senator Elizabeth Warren, who is competing...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>https://www.wnd.com/2019/04/12-french-churches...</td>\n",
       "      <td>WND Staff</td>\n",
       "      <td>Tue, 16 Apr 2019 11:53:00 GMT</td>\n",
       "      <td>12 French churches attacked before Notre Dame ...</td>\n",
       "      <td>Only hours after the first flames that eventua...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>WorldNetDaily</td>\n",
       "      <td>19.75</td>\n",
       "      <td>19.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>https://www.wnd.com/2019/04/doj-sued-for-detai...</td>\n",
       "      <td>WND Staff</td>\n",
       "      <td>Tue, 16 Apr 2019 19:16:00 GMT</td>\n",
       "      <td>DOJ sued for details of payments to Christophe...</td>\n",
       "      <td>Washington watchdog Judicial Watch believes th...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WorldNetDaily</td>\n",
       "      <td>30.50</td>\n",
       "      <td>21.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>https://www.wnd.com/2019/04/fox-news-stars-pul...</td>\n",
       "      <td>WND Staff</td>\n",
       "      <td>Tue, 16 Apr 2019 14:23:00 GMT</td>\n",
       "      <td>Fox News stars pull plug on history of church ...</td>\n",
       "      <td>Two Fox News personalities, as Notre Dame Cath...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>WorldNetDaily</td>\n",
       "      <td>29.75</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>https://www.wnd.com/2019/04/major-u-s-bank-shu...</td>\n",
       "      <td>WND Staff</td>\n",
       "      <td>Tue, 16 Apr 2019 16:37:00 GMT</td>\n",
       "      <td>Major U.S. bank shuts down 'alt-right' accounts</td>\n",
       "      <td>Chase Bank is shutting down accounts of people...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>WorldNetDaily</td>\n",
       "      <td>22.00</td>\n",
       "      <td>25.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>https://www.wnd.com/2019/04/schiff-launches-ne...</td>\n",
       "      <td>WND Staff</td>\n",
       "      <td>Tue, 16 Apr 2019 18:26:00 GMT</td>\n",
       "      <td>Schiff launches next front in war against Trump</td>\n",
       "      <td>Rep. Adam Schiff, D-Calif., unwilling to give ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WorldNetDaily</td>\n",
       "      <td>26.00</td>\n",
       "      <td>23.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1675 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Url           Author  \\\n",
       "0     https://abcnews.go.com/Politics/abortion-right...      Devin Dwyer   \n",
       "1     https://abcnews.go.com/Politics/appeals-court-...      Ali Dukakis   \n",
       "2     https://abcnews.go.com/Politics/attorney-gener...        Luke Barr   \n",
       "3     https://abcnews.go.com/Politics/donald-trump-t...  Meridith McGraw   \n",
       "4     https://abcnews.go.com/Politics/electoral-coll...     Matthew Dowd   \n",
       "...                                                 ...              ...   \n",
       "1670  https://www.wnd.com/2019/04/12-french-churches...        WND Staff   \n",
       "1671  https://www.wnd.com/2019/04/doj-sued-for-detai...        WND Staff   \n",
       "1672  https://www.wnd.com/2019/04/fox-news-stars-pul...        WND Staff   \n",
       "1673  https://www.wnd.com/2019/04/major-u-s-bank-shu...        WND Staff   \n",
       "1674  https://www.wnd.com/2019/04/schiff-launches-ne...        WND Staff   \n",
       "\n",
       "                               Date  \\\n",
       "0     Wed, 17 Apr 2019 10:14:00 GMT   \n",
       "1     Tue, 26 Feb 2019 09:05:00 GMT   \n",
       "2     Wed, 17 Apr 2019 14:02:00 GMT   \n",
       "3     Tue, 19 Mar 2019 12:44:00 GMT   \n",
       "4     Tue, 19 Mar 2019 21:39:00 GMT   \n",
       "...                             ...   \n",
       "1670  Tue, 16 Apr 2019 11:53:00 GMT   \n",
       "1671  Tue, 16 Apr 2019 19:16:00 GMT   \n",
       "1672  Tue, 16 Apr 2019 14:23:00 GMT   \n",
       "1673  Tue, 16 Apr 2019 16:37:00 GMT   \n",
       "1674  Tue, 16 Apr 2019 18:26:00 GMT   \n",
       "\n",
       "                                                 Header  \\\n",
       "0     Abortion rights group asks Supreme Court to st...   \n",
       "1     Appeals court says special counsel Robert Muel...   \n",
       "2     Attorney general orders some asylum seekers to...   \n",
       "3     Donald Trump and 'the Trump of the Tropics,' B...   \n",
       "4     The Electoral College limits the campaign play...   \n",
       "...                                                 ...   \n",
       "1670  12 French churches attacked before Notre Dame ...   \n",
       "1671  DOJ sued for details of payments to Christophe...   \n",
       "1672  Fox News stars pull plug on history of church ...   \n",
       "1673    Major U.S. bank shuts down 'alt-right' accounts   \n",
       "1674    Schiff launches next front in war against Trump   \n",
       "\n",
       "                                                   Body  n_links  \\\n",
       "0     Abortion rights advocates have asked the U.S. ...      3.0   \n",
       "1     A federal appeals court rejected the most dire...      2.0   \n",
       "2     As part of the Trump administration's effort t...      6.0   \n",
       "3     President Donald Trump and \"the Trump of the T...     10.0   \n",
       "4     U.S Senator Elizabeth Warren, who is competing...      5.0   \n",
       "...                                                 ...      ...   \n",
       "1670  Only hours after the first flames that eventua...     18.0   \n",
       "1671  Washington watchdog Judicial Watch believes th...      2.0   \n",
       "1672  Two Fox News personalities, as Notre Dame Cath...      7.0   \n",
       "1673  Chase Bank is shutting down accounts of people...      3.0   \n",
       "1674  Rep. Adam Schiff, D-Calif., unwilling to give ...      2.0   \n",
       "\n",
       "             Source   Bias  Quality  \n",
       "0               ABC   1.67    49.00  \n",
       "1               ABC   0.67    51.67  \n",
       "2               ABC  -2.75    43.50  \n",
       "3               ABC  -4.33    52.67  \n",
       "4               ABC -10.00    32.00  \n",
       "...             ...    ...      ...  \n",
       "1670  WorldNetDaily  19.75    19.75  \n",
       "1671  WorldNetDaily  30.50    21.25  \n",
       "1672  WorldNetDaily  29.75    12.00  \n",
       "1673  WorldNetDaily  22.00    25.25  \n",
       "1674  WorldNetDaily  26.00    23.25  \n",
       "\n",
       "[1675 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_csv('/Users/daviddeng8/affinity/data/outlet_data.csv')\n",
    "#data['content'][:100]\n",
    "data = pd.read_csv('/Users/daviddeng8/Documents/Projects/affinity/data/final_data.csv')\n",
    "#data.loc[261, 'Url']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPOS(words):\n",
    "    #return nltk.pos_tag(word)\n",
    "    return [(word, get_wordnet_pos(word)) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndividualPOS(word):\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV} \n",
    "    tag = nltk.pos_tag(word[0].upper())\n",
    "    return tag_dict.get(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.machinelearningplus.com/nlp/lemmatization-examples-python/\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}    \n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hello', 'n'), ('bye', 'n')]\n"
     ]
    }
   ],
   "source": [
    "print (getPOS(['hello', 'bye']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    \n",
    "    #removing stopwords and punctuation\n",
    "    tokenized = nltk.word_tokenize(row['Body'])\n",
    "    temp = [word for word in tokenized if word.lower() not in wordsToCut and word not in string.punctuation and word.isalpha()]\n",
    "    \n",
    "    #row['Body'] = ' '.join(temp)\n",
    "    \n",
    "    #row['Body'] = [word for word in nltk.word_tokenize(row['Body']) if word not in wordsToCut]\n",
    "    #row['Body'] = row['Body'].lower()\n",
    "    #nopunc = [char for char in row['Body'] if char not in string.punctuation]\n",
    "    #nopunc.join('')\n",
    "    \n",
    "    #lemmatizing, ONLY KEEPING ENTITIES\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    partsOfSpeech = getPOS(temp)\n",
    "    \n",
    "    lemmatized = [lemmatizer.lemmatize(word, pos) for word, pos in partsOfSpeech if pos == 'n']\n",
    "    final = ' '.join(lemmatized)\n",
    "    data.at[index, 'Body'] = final\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Url</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Body</th>\n",
       "      <th>n_links</th>\n",
       "      <th>Source</th>\n",
       "      <th>Bias</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://abcnews.go.com/Politics/abortion-right...</td>\n",
       "      <td>Devin Dwyer</td>\n",
       "      <td>Wed, 17 Apr 2019 10:14:00 GMT</td>\n",
       "      <td>Abortion rights group asks Supreme Court to st...</td>\n",
       "      <td>Abortion right advocate Supreme Court strike L...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>1.67</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://abcnews.go.com/Politics/appeals-court-...</td>\n",
       "      <td>Ali Dukakis</td>\n",
       "      <td>Tue, 26 Feb 2019 09:05:00 GMT</td>\n",
       "      <td>Appeals court says special counsel Robert Muel...</td>\n",
       "      <td>appeal court challenge counsel Robert Mueller ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>0.67</td>\n",
       "      <td>51.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://abcnews.go.com/Politics/attorney-gener...</td>\n",
       "      <td>Luke Barr</td>\n",
       "      <td>Wed, 17 Apr 2019 14:02:00 GMT</td>\n",
       "      <td>Attorney general orders some asylum seekers to...</td>\n",
       "      <td>part Trump administration effort migrant borde...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>43.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://abcnews.go.com/Politics/donald-trump-t...</td>\n",
       "      <td>Meridith McGraw</td>\n",
       "      <td>Tue, 19 Mar 2019 12:44:00 GMT</td>\n",
       "      <td>Donald Trump and 'the Trump of the Tropics,' B...</td>\n",
       "      <td>President Donald Trump Trump Tropics president...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>52.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://abcnews.go.com/Politics/electoral-coll...</td>\n",
       "      <td>Matthew Dowd</td>\n",
       "      <td>Tue, 19 Mar 2019 21:39:00 GMT</td>\n",
       "      <td>The Electoral College limits the campaign play...</td>\n",
       "      <td>Senator Elizabeth Warren nomination president ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>https://www.wnd.com/2019/04/12-french-churches...</td>\n",
       "      <td>WND Staff</td>\n",
       "      <td>Tue, 16 Apr 2019 11:53:00 GMT</td>\n",
       "      <td>12 French churches attacked before Notre Dame ...</td>\n",
       "      <td>hour flame would consume Notre Dame roof spire...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>WorldNetDaily</td>\n",
       "      <td>19.75</td>\n",
       "      <td>19.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>https://www.wnd.com/2019/04/doj-sued-for-detai...</td>\n",
       "      <td>WND Staff</td>\n",
       "      <td>Tue, 16 Apr 2019 19:16:00 GMT</td>\n",
       "      <td>DOJ sued for details of payments to Christophe...</td>\n",
       "      <td>Washington watchdog Watch FBI information orig...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WorldNetDaily</td>\n",
       "      <td>30.50</td>\n",
       "      <td>21.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>https://www.wnd.com/2019/04/fox-news-stars-pul...</td>\n",
       "      <td>WND Staff</td>\n",
       "      <td>Tue, 16 Apr 2019 14:23:00 GMT</td>\n",
       "      <td>Fox News stars pull plug on history of church ...</td>\n",
       "      <td>Two Fox News personality Notre Dame Paris engu...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>WorldNetDaily</td>\n",
       "      <td>29.75</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>https://www.wnd.com/2019/04/major-u-s-bank-shu...</td>\n",
       "      <td>WND Staff</td>\n",
       "      <td>Tue, 16 Apr 2019 16:37:00 GMT</td>\n",
       "      <td>Major U.S. bank shuts down 'alt-right' accounts</td>\n",
       "      <td>Chase Bank account people organization view un...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>WorldNetDaily</td>\n",
       "      <td>22.00</td>\n",
       "      <td>25.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>https://www.wnd.com/2019/04/schiff-launches-ne...</td>\n",
       "      <td>WND Staff</td>\n",
       "      <td>Tue, 16 Apr 2019 18:26:00 GMT</td>\n",
       "      <td>Schiff launches next front in war against Trump</td>\n",
       "      <td>Adam Schiff claim Donald Trump Russia despite ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>WorldNetDaily</td>\n",
       "      <td>26.00</td>\n",
       "      <td>23.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1675 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Url           Author  \\\n",
       "0     https://abcnews.go.com/Politics/abortion-right...      Devin Dwyer   \n",
       "1     https://abcnews.go.com/Politics/appeals-court-...      Ali Dukakis   \n",
       "2     https://abcnews.go.com/Politics/attorney-gener...        Luke Barr   \n",
       "3     https://abcnews.go.com/Politics/donald-trump-t...  Meridith McGraw   \n",
       "4     https://abcnews.go.com/Politics/electoral-coll...     Matthew Dowd   \n",
       "...                                                 ...              ...   \n",
       "1670  https://www.wnd.com/2019/04/12-french-churches...        WND Staff   \n",
       "1671  https://www.wnd.com/2019/04/doj-sued-for-detai...        WND Staff   \n",
       "1672  https://www.wnd.com/2019/04/fox-news-stars-pul...        WND Staff   \n",
       "1673  https://www.wnd.com/2019/04/major-u-s-bank-shu...        WND Staff   \n",
       "1674  https://www.wnd.com/2019/04/schiff-launches-ne...        WND Staff   \n",
       "\n",
       "                               Date  \\\n",
       "0     Wed, 17 Apr 2019 10:14:00 GMT   \n",
       "1     Tue, 26 Feb 2019 09:05:00 GMT   \n",
       "2     Wed, 17 Apr 2019 14:02:00 GMT   \n",
       "3     Tue, 19 Mar 2019 12:44:00 GMT   \n",
       "4     Tue, 19 Mar 2019 21:39:00 GMT   \n",
       "...                             ...   \n",
       "1670  Tue, 16 Apr 2019 11:53:00 GMT   \n",
       "1671  Tue, 16 Apr 2019 19:16:00 GMT   \n",
       "1672  Tue, 16 Apr 2019 14:23:00 GMT   \n",
       "1673  Tue, 16 Apr 2019 16:37:00 GMT   \n",
       "1674  Tue, 16 Apr 2019 18:26:00 GMT   \n",
       "\n",
       "                                                 Header  \\\n",
       "0     Abortion rights group asks Supreme Court to st...   \n",
       "1     Appeals court says special counsel Robert Muel...   \n",
       "2     Attorney general orders some asylum seekers to...   \n",
       "3     Donald Trump and 'the Trump of the Tropics,' B...   \n",
       "4     The Electoral College limits the campaign play...   \n",
       "...                                                 ...   \n",
       "1670  12 French churches attacked before Notre Dame ...   \n",
       "1671  DOJ sued for details of payments to Christophe...   \n",
       "1672  Fox News stars pull plug on history of church ...   \n",
       "1673    Major U.S. bank shuts down 'alt-right' accounts   \n",
       "1674    Schiff launches next front in war against Trump   \n",
       "\n",
       "                                                   Body  n_links  \\\n",
       "0     Abortion right advocate Supreme Court strike L...      3.0   \n",
       "1     appeal court challenge counsel Robert Mueller ...      2.0   \n",
       "2     part Trump administration effort migrant borde...      6.0   \n",
       "3     President Donald Trump Trump Tropics president...     10.0   \n",
       "4     Senator Elizabeth Warren nomination president ...      5.0   \n",
       "...                                                 ...      ...   \n",
       "1670  hour flame would consume Notre Dame roof spire...     18.0   \n",
       "1671  Washington watchdog Watch FBI information orig...      2.0   \n",
       "1672  Two Fox News personality Notre Dame Paris engu...      7.0   \n",
       "1673  Chase Bank account people organization view un...      3.0   \n",
       "1674  Adam Schiff claim Donald Trump Russia despite ...      2.0   \n",
       "\n",
       "             Source   Bias  Quality  \n",
       "0               ABC   1.67    49.00  \n",
       "1               ABC   0.67    51.67  \n",
       "2               ABC  -2.75    43.50  \n",
       "3               ABC  -4.33    52.67  \n",
       "4               ABC -10.00    32.00  \n",
       "...             ...    ...      ...  \n",
       "1670  WorldNetDaily  19.75    19.75  \n",
       "1671  WorldNetDaily  30.50    21.25  \n",
       "1672  WorldNetDaily  29.75    12.00  \n",
       "1673  WorldNetDaily  22.00    25.25  \n",
       "1674  WorldNetDaily  26.00    23.25  \n",
       "\n",
       "[1675 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aapl</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarp</th>\n",
       "      <th>ababa</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abby</th>\n",
       "      <th>...</th>\n",
       "      <th>zumba</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zwiebel</th>\n",
       "      <th>√°gua</th>\n",
       "      <th>√•slund</th>\n",
       "      <th>√©douard</th>\n",
       "      <th>√©galit√©</th>\n",
       "      <th>√©lectricit√©</th>\n",
       "      <th>ùôπùöûùöäùöó</th>\n",
       "      <th>ùöÅùöòùöçùöõùöíùöêùöûùöéùö£</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>837 rows √ó 17264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aapl  aaron  aarp  ababa  aback  abandon  abandonment  abbey  \\\n",
       "0     0.0    0.0   0.0    0.0    0.0      0.0          0.0    0.0   \n",
       "1     0.0    0.0   0.0    0.0    0.0      0.0          0.0    0.0   \n",
       "2     0.0    0.0   0.0    0.0    0.0      0.0          0.0    0.0   \n",
       "3     0.0    0.0   0.0    0.0    0.0      0.0          0.0    0.0   \n",
       "4     0.0    0.0   0.0    0.0    0.0      0.0          0.0    0.0   \n",
       "..    ...    ...   ...    ...    ...      ...          ...    ...   \n",
       "832   0.0    0.0   0.0    0.0    0.0      0.0          0.0    0.0   \n",
       "833   0.0    0.0   0.0    0.0    0.0      0.0          0.0    0.0   \n",
       "834   0.0    0.0   0.0    0.0    0.0      0.0          0.0    0.0   \n",
       "835   0.0    0.0   0.0    0.0    0.0      0.0          0.0    0.0   \n",
       "836   0.0    0.0   0.0    0.0    0.0      0.0          0.0    0.0   \n",
       "\n",
       "     abbreviation  abby  ...  zumba  zurich  zwiebel  √°gua  √•slund  √©douard  \\\n",
       "0             0.0   0.0  ...    0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "1             0.0   0.0  ...    0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "2             0.0   0.0  ...    0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "3             0.0   0.0  ...    0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "4             0.0   0.0  ...    0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "..            ...   ...  ...    ...     ...      ...   ...     ...      ...   \n",
       "832           0.0   0.0  ...    0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "833           0.0   0.0  ...    0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "834           0.0   0.0  ...    0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "835           0.0   0.0  ...    0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "836           0.0   0.0  ...    0.0     0.0      0.0   0.0     0.0      0.0   \n",
       "\n",
       "     √©galit√©  √©lectricit√©  ùôπùöûùöäùöó  ùöÅùöòùöçùöõùöíùöêùöûùöéùö£  \n",
       "0        0.0          0.0   0.0        0.0  \n",
       "1        0.0          0.0   0.0        0.0  \n",
       "2        0.0          0.0   0.0        0.0  \n",
       "3        0.0          0.0   0.0        0.0  \n",
       "4        0.0          0.0   0.0        0.0  \n",
       "..       ...          ...   ...        ...  \n",
       "832      0.0          0.0   0.0        0.0  \n",
       "833      0.0          0.0   0.0        0.0  \n",
       "834      0.0          0.0   0.0        0.0  \n",
       "835      0.0          0.0   0.0        0.0  \n",
       "836      0.0          0.0   0.0        0.0  \n",
       "\n",
       "[837 rows x 17264 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf = True, stop_words = 'english')\n",
    "#matrix = vectorizer.fit_transform(data['Body'])\n",
    "matrix = vectorizer.fit_transform(train['Body'])\n",
    "df = pd.DataFrame(matrix.toarray(), columns = vectorizer.get_feature_names())\n",
    "#list comprehension\n",
    "#x = np.where(df['√©lectricit√©'] != 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaf</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aapl</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aarp</th>\n",
       "      <th>aarseth</th>\n",
       "      <th>ababa</th>\n",
       "      <th>aback</th>\n",
       "      <th>...</th>\n",
       "      <th>√©douard</th>\n",
       "      <th>√©galit√©</th>\n",
       "      <th>√©lectricit√©</th>\n",
       "      <th>√©lys√©e</th>\n",
       "      <th>√©migr√©</th>\n",
       "      <th>√©tat</th>\n",
       "      <th>√Æle</th>\n",
       "      <th>√∏ystein</th>\n",
       "      <th>ùôπùöûùöäùöó</th>\n",
       "      <th>ùöÅùöòùöçùöõùöíùöêùöûùöéùö£</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1675 rows √ó 24352 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaa  aaf  aaliyah  aapl  aaron  aarp  aarseth  ababa  aback  ...  \\\n",
       "0     0.0  0.0  0.0      0.0   0.0    0.0   0.0      0.0    0.0    0.0  ...   \n",
       "1     0.0  0.0  0.0      0.0   0.0    0.0   0.0      0.0    0.0    0.0  ...   \n",
       "2     0.0  0.0  0.0      0.0   0.0    0.0   0.0      0.0    0.0    0.0  ...   \n",
       "3     0.0  0.0  0.0      0.0   0.0    0.0   0.0      0.0    0.0    0.0  ...   \n",
       "4     0.0  0.0  0.0      0.0   0.0    0.0   0.0      0.0    0.0    0.0  ...   \n",
       "...   ...  ...  ...      ...   ...    ...   ...      ...    ...    ...  ...   \n",
       "1670  0.0  0.0  0.0      0.0   0.0    0.0   0.0      0.0    0.0    0.0  ...   \n",
       "1671  0.0  0.0  0.0      0.0   0.0    0.0   0.0      0.0    0.0    0.0  ...   \n",
       "1672  0.0  0.0  0.0      0.0   0.0    0.0   0.0      0.0    0.0    0.0  ...   \n",
       "1673  0.0  0.0  0.0      0.0   0.0    0.0   0.0      0.0    0.0    0.0  ...   \n",
       "1674  0.0  0.0  0.0      0.0   0.0    0.0   0.0      0.0    0.0    0.0  ...   \n",
       "\n",
       "      √©douard  √©galit√©  √©lectricit√©  √©lys√©e  √©migr√©  √©tat  √Æle  √∏ystein  ùôπùöûùöäùöó  \\\n",
       "0         0.0      0.0          0.0     0.0     0.0   0.0  0.0      0.0   0.0   \n",
       "1         0.0      0.0          0.0     0.0     0.0   0.0  0.0      0.0   0.0   \n",
       "2         0.0      0.0          0.0     0.0     0.0   0.0  0.0      0.0   0.0   \n",
       "3         0.0      0.0          0.0     0.0     0.0   0.0  0.0      0.0   0.0   \n",
       "4         0.0      0.0          0.0     0.0     0.0   0.0  0.0      0.0   0.0   \n",
       "...       ...      ...          ...     ...     ...   ...  ...      ...   ...   \n",
       "1670      0.0      0.0          0.0     0.0     0.0   0.0  0.0      0.0   0.0   \n",
       "1671      0.0      0.0          0.0     0.0     0.0   0.0  0.0      0.0   0.0   \n",
       "1672      0.0      0.0          0.0     0.0     0.0   0.0  0.0      0.0   0.0   \n",
       "1673      0.0      0.0          0.0     0.0     0.0   0.0  0.0      0.0   0.0   \n",
       "1674      0.0      0.0          0.0     0.0     0.0   0.0  0.0      0.0   0.0   \n",
       "\n",
       "      ùöÅùöòùöçùöõùöíùöêùöûùöéùö£  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "...         ...  \n",
       "1670        0.0  \n",
       "1671        0.0  \n",
       "1672        0.0  \n",
       "1673        0.0  \n",
       "1674        0.0  \n",
       "\n",
       "[1675 rows x 24352 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df = df.drop([columnName for (columnName, columnData) in df.iteritems() if columnName.isalpha() == False], axis=1)\n",
    "matrix = vectorizer.fit_transform(df)\n",
    "temp = pd.DataFrame(matrix.toarray(), columns = vectorizer.get_feature_names())\n",
    "temp'''\n",
    "matrix = vectorizer.fit_transform(data['Body'])\n",
    "temp = pd.DataFrame(matrix.toarray(), columns = vectorizer.get_feature_names())\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=50, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_clusters = 50\n",
    "model = KMeans(n_clusters = number_of_clusters)\n",
    "model.fit(matrix)\n",
    "\n",
    "# elbow method, silhouette score\n",
    "# entity recognition: do the same clustering but with only entities (nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for number of cluster(s) 2: -799.5346045941839\n",
      "Silhouette score for number of cluster(s) 2: 0.007869515052423198\n",
      "Score for number of cluster(s) 3: -790.4660782583998\n",
      "Silhouette score for number of cluster(s) 3: 0.007535767122196954\n",
      "Score for number of cluster(s) 4: -786.5923519614713\n",
      "Silhouette score for number of cluster(s) 4: 0.008839203913181527\n",
      "Score for number of cluster(s) 5: -780.7645930289345\n",
      "Silhouette score for number of cluster(s) 5: 0.010971050894623267\n",
      "Score for number of cluster(s) 6: -777.9422488756032\n",
      "Silhouette score for number of cluster(s) 6: 0.011275517499811987\n",
      "Score for number of cluster(s) 7: -773.2725503292794\n",
      "Silhouette score for number of cluster(s) 7: 0.014538146669683125\n",
      "Score for number of cluster(s) 8: -768.2870827224546\n",
      "Silhouette score for number of cluster(s) 8: 0.016023504916522935\n",
      "Score for number of cluster(s) 9: -763.1080651034039\n",
      "Silhouette score for number of cluster(s) 9: 0.019599728676635446\n",
      "Score for number of cluster(s) 10: -758.7565669763413\n",
      "Silhouette score for number of cluster(s) 10: 0.020390214366595247\n",
      "Score for number of cluster(s) 11: -755.1654775939257\n",
      "Silhouette score for number of cluster(s) 11: 0.021131678792508334\n",
      "Score for number of cluster(s) 12: -754.7719562959619\n",
      "Silhouette score for number of cluster(s) 12: 0.021309789211941533\n",
      "Score for number of cluster(s) 13: -750.6112493478464\n",
      "Silhouette score for number of cluster(s) 13: 0.023563293155898887\n",
      "Score for number of cluster(s) 14: -745.6805170161617\n",
      "Silhouette score for number of cluster(s) 14: 0.02361932924131184\n",
      "Score for number of cluster(s) 15: -744.087880442857\n",
      "Silhouette score for number of cluster(s) 15: 0.023869831139143885\n",
      "Score for number of cluster(s) 16: -740.2368744054908\n",
      "Silhouette score for number of cluster(s) 16: 0.025307535615750217\n",
      "Score for number of cluster(s) 17: -738.0114730128519\n",
      "Silhouette score for number of cluster(s) 17: 0.029158152325938512\n",
      "Score for number of cluster(s) 18: -733.3677917225876\n",
      "Silhouette score for number of cluster(s) 18: 0.03243509039984211\n",
      "Score for number of cluster(s) 19: -728.0481993349897\n",
      "Silhouette score for number of cluster(s) 19: 0.03526188487809144\n",
      "Score for number of cluster(s) 20: -726.7960531447172\n",
      "Silhouette score for number of cluster(s) 20: 0.03545488827692328\n",
      "Score for number of cluster(s) 21: -724.2595998884809\n",
      "Silhouette score for number of cluster(s) 21: 0.034315082227769224\n",
      "Score for number of cluster(s) 22: -723.0406160868024\n",
      "Silhouette score for number of cluster(s) 22: 0.03459403265500423\n",
      "Score for number of cluster(s) 23: -719.1993147976403\n",
      "Silhouette score for number of cluster(s) 23: 0.035020784738832605\n",
      "Score for number of cluster(s) 24: -716.4807474864308\n",
      "Silhouette score for number of cluster(s) 24: 0.034273675193473234\n",
      "Score for number of cluster(s) 25: -714.8675228446269\n",
      "Silhouette score for number of cluster(s) 25: 0.034657041316593466\n",
      "Score for number of cluster(s) 26: -712.2783972101638\n",
      "Silhouette score for number of cluster(s) 26: 0.035590229651786216\n",
      "Score for number of cluster(s) 27: -708.5932860070426\n",
      "Silhouette score for number of cluster(s) 27: 0.037687392533207284\n",
      "Score for number of cluster(s) 28: -706.9591961445208\n",
      "Silhouette score for number of cluster(s) 28: 0.03927771209390258\n",
      "Score for number of cluster(s) 29: -704.4564211677501\n",
      "Silhouette score for number of cluster(s) 29: 0.035362377020124694\n",
      "Score for number of cluster(s) 30: -702.5436949972158\n",
      "Silhouette score for number of cluster(s) 30: 0.0357613413372921\n",
      "Score for number of cluster(s) 31: -699.9174920871948\n",
      "Silhouette score for number of cluster(s) 31: 0.04300720345226567\n",
      "Score for number of cluster(s) 32: -698.4473793314862\n",
      "Silhouette score for number of cluster(s) 32: 0.043152830218620174\n",
      "Score for number of cluster(s) 33: -696.3314618535846\n",
      "Silhouette score for number of cluster(s) 33: 0.044520813954078746\n",
      "Score for number of cluster(s) 34: -693.4707644504306\n",
      "Silhouette score for number of cluster(s) 34: 0.041303918384061764\n",
      "Score for number of cluster(s) 35: -691.9028088194631\n",
      "Silhouette score for number of cluster(s) 35: 0.039864758783327625\n",
      "Score for number of cluster(s) 36: -690.2345416427735\n",
      "Silhouette score for number of cluster(s) 36: 0.03951210503380103\n",
      "Score for number of cluster(s) 37: -686.9015125649985\n",
      "Silhouette score for number of cluster(s) 37: 0.043908719346235955\n",
      "Score for number of cluster(s) 38: -685.1878220112237\n",
      "Silhouette score for number of cluster(s) 38: 0.04422861193947006\n",
      "Score for number of cluster(s) 39: -683.828102637378\n",
      "Silhouette score for number of cluster(s) 39: 0.044505794317737414\n",
      "Score for number of cluster(s) 40: -681.7614456233866\n",
      "Silhouette score for number of cluster(s) 40: 0.044932430932618526\n",
      "Score for number of cluster(s) 41: -679.0480944135052\n",
      "Silhouette score for number of cluster(s) 41: 0.04633310945893757\n",
      "Score for number of cluster(s) 42: -675.9568596981779\n",
      "Silhouette score for number of cluster(s) 42: 0.0471154120637944\n",
      "Score for number of cluster(s) 43: -673.8737754860605\n",
      "Silhouette score for number of cluster(s) 43: 0.04954165594744792\n",
      "Score for number of cluster(s) 44: -672.7346568489454\n",
      "Silhouette score for number of cluster(s) 44: 0.049549597488606295\n",
      "Score for number of cluster(s) 45: -669.3798188211036\n",
      "Silhouette score for number of cluster(s) 45: 0.05138538951117549\n",
      "Score for number of cluster(s) 46: -667.6212547099491\n",
      "Silhouette score for number of cluster(s) 46: 0.05206622425418437\n",
      "Score for number of cluster(s) 47: -664.1990083650194\n",
      "Silhouette score for number of cluster(s) 47: 0.05321944798184488\n",
      "Score for number of cluster(s) 48: -663.3845015464093\n",
      "Silhouette score for number of cluster(s) 48: 0.05286922299733075\n",
      "Score for number of cluster(s) 49: -662.3765612157526\n",
      "Silhouette score for number of cluster(s) 49: 0.05262215726921963\n"
     ]
    }
   ],
   "source": [
    "km_scores= []\n",
    "km_silhouette = []\n",
    "vmeasure_score =[]\n",
    "db_score = []\n",
    "for i in range(2,50):\n",
    "    km = KMeans(n_clusters=i, random_state=0).fit(matrix)\n",
    "    preds = km.predict(matrix)\n",
    "    \n",
    "    print(\"Score for number of cluster(s) {}: {}\".format(i,km.score(matrix)))\n",
    "    km_scores.append(-km.score(matrix))\n",
    "    \n",
    "    silhouette = silhouette_score(matrix,preds)\n",
    "    km_silhouette.append(silhouette)\n",
    "    print(\"Silhouette score for number of cluster(s) {}: {}\".format(i,silhouette))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(km_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "plt.scatter(x = [i for i in range(2, 50)], y = km_scores)\n",
    "plt.xlabel('number of clusters', fontsize=20)\n",
    "plt.ylabel('elbow method score', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "plt.scatter(x = [i for i in range(2, 50)], y = km_silhouette)\n",
    "plt.xlabel('number of clusters', fontsize = 20)\n",
    "plt.ylabel('silhouette score', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_clusters = 50\n",
    "model = KMeans(n_clusters = number_of_clusters)\n",
    "model.fit(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(number_of_clusters):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "gapminder_url='https://bit.ly/2cLzoxH'\n",
    "gapminder = pd.read_csv(gapminder_url)\n",
    "gapminder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapminder_ocean = gapminder[(gapminder.year > 2000) & (gapminder.continent == 'Oceania')]\n",
    "gapminder_ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = gapminder_ocean.drop([columnName for (columnName, columnData) in gapminder_ocean.iteritems() if columnName == 'pop'], axis = 1)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['69'] = [0, 0, 0, 0]\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = new.drop([columnName if ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_old = pd.read_csv('/Users/daviddeng8/Documents/Projects/affinity/data/outlet_data.csv')\n",
    "\n",
    "vectorizer_old = TfidfVectorizer(use_idf = True, stop_words = 'english')\n",
    "matrix_old = vectorizer.fit_transform(data_old['content'])\n",
    "df_old = pd.DataFrame(matrix_old.toarray(), columns = vectorizer.get_feature_names())\n",
    "df_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_clusters_old = 50\n",
    "model_old = KMeans(n_clusters = number_of_clusters_old)\n",
    "model_old.fit(matrix_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids_old = model_old.cluster_centers_.argsort()[:, ::-1]\n",
    "terms_old = vectorizer_old.get_feature_names()\n",
    "for i in range(number_of_clusters_old):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids_old[i, :10]:\n",
    "        print(' %s' % terms_old[ind]),\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_scores_old= []\n",
    "km_silhouette_old = []\n",
    "vmeasure_score_old =[]\n",
    "db_score_old = []\n",
    "for i in range(2,50):\n",
    "    km_old = KMeans(n_clusters=i, random_state=0).fit(matrix_old)\n",
    "    preds_old = km_old.predict(matrix_old)\n",
    "    \n",
    "    print(\"Score for number of cluster(s) {}: {}\".format(i,km_old.score(matrix)))\n",
    "    km_scores_old.append(-km_old.score(matrix_old))\n",
    "    \n",
    "    silhouette_old = silhouette_score_old(matrix_old,preds_old)\n",
    "    km_silhouette_old.append(silhouette_old)\n",
    "    print(\"Silhouette score for number of cluster(s) {}: {}\".format(i,silhouette_old))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
