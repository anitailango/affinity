{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Universal Sentence Encoder Demo\n",
    "\n",
    "The Universal Sentence Encoder model is ~1 GB, so loading at first may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Universal Sentence Encoder from TF Hub\n",
    "use_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "embed = hub.load(use_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.03133018 -0.06338634 -0.01607502 ... -0.03242778 -0.04575741\n",
      "   0.05370456]\n",
      " [ 0.05080861 -0.01652428  0.01573781 ...  0.00976659  0.03170123\n",
      "   0.0178812 ]], shape=(2, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_sentences = [\"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"I am a sentence for which I would like to get its embedding\"]\n",
    "print(embed(input_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  rating\n",
      "0  smart and alert , thirteen conversations about...       0\n",
      "1  color , musical bounce and warm seas lapping o...       0\n",
      "2  it is not a mass-market entertainment but an u...       0\n",
      "3  a light-hearted french film about the spiritua...       0\n",
      "4  my wife is an actress has its moments in looki...       0\n",
      "                                               sentence  rating\n",
      "9995  in the end , they discover that balance in lif...       1\n",
      "9996  a counterfeit 1000 tomin bank note is passed i...       1\n",
      "9997  enter the beautiful and mysterious secret agen...       1\n",
      "9998  after listening to a missionary from china spe...       1\n",
      "9999  looking for a short cut to fame , glass concoc...       1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/movie_sentences.csv\")\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.KerasLayer(use_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = tf.keras.layers.Dense(32, activation='relu')\n",
    "dropout = tf.keras.layers.Dropout(0.2)\n",
    "output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = embed(tf.squeeze(tf.cast(inputs, tf.string)))\n",
    "x = dense1(x)\n",
    "x = dropout(x)\n",
    "outputs = output_layer(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.1228 - accuracy: 0.8416\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0797 - accuracy: 0.9137\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0743 - accuracy: 0.9211\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0705 - accuracy: 0.9266\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.0682 - accuracy: 0.9298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x142e9ed10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train['sentence'], train['rating'], epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0718 - accuracy: 0.9170\n",
      "Test Loss: 0.07178784161806107, Test Accuracy: 0.9169999957084656\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test['sentence'], test['rating'])\n",
    "print(\"Test Loss: {}, Test Accuracy: {}\".format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-04e1129aa18d>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-04e1129aa18d>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    classification = if score > 0.5 \"Objective\" else \"Subjective\"\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "demo_sentences = np.array([\n",
    "    \"The Earth is round\",\n",
    "    \"This sandwich tastes bad\",\n",
    "    \"The committee probe started in January 2017 under then-Chair Devin Nunes and concluded in March 2018 with a report finding no evidence that the Trump campaign conspired with the Kremlin\",\n",
    "    \"He misled the country repeatedly on an issue that consumed American politics\",\n",
    "    \"As for Mr. Schiff, no one should ever believe another word he says\"\n",
    "])\n",
    "scores = np.array(model(demo_sentences))\n",
    "for i, score in enumerate(scores):\n",
    "    classification = \"Objective\" if score > 0.5 else \"Subjective\"\n",
    "    print (\"{}\\nScore: {}\\n ({})\".format(demo_sentences[i], score[0], classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python37664bitvenvvenv9876d6e4437248b6980ed0dfa825a84b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
