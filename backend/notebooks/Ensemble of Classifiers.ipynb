{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/preprocessed_cleaned_body.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Bias</th>\n",
       "      <th>cleaned_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abortion rights advocates have asked the U.S. ...</td>\n",
       "      <td>1.67</td>\n",
       "      <td>abortion right advocate asked u supreme court ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A federal appeals court rejected the most dire...</td>\n",
       "      <td>0.67</td>\n",
       "      <td>federal appeal court rejected direct constitut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As part of the Trump administration's effort t...</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>part trump administration effort slow migrant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>President Donald Trump and \"the Trump of the T...</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>president donald trump trump tropic brazilian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.S Senator Elizabeth Warren, who is competing...</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>u senator elizabeth warren competing democrati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body   Bias  \\\n",
       "0  Abortion rights advocates have asked the U.S. ...   1.67   \n",
       "1  A federal appeals court rejected the most dire...   0.67   \n",
       "2  As part of the Trump administration's effort t...  -2.75   \n",
       "3  President Donald Trump and \"the Trump of the T...  -4.33   \n",
       "4  U.S Senator Elizabeth Warren, who is competing... -10.00   \n",
       "\n",
       "                                        cleaned_body  \n",
       "0  abortion right advocate asked u supreme court ...  \n",
       "1  federal appeal court rejected direct constitut...  \n",
       "2  part trump administration effort slow migrant ...  \n",
       "3  president donald trump trump tropic brazilian ...  \n",
       "4  u senator elizabeth warren competing democrati...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 represents most left, 3 represents most right\n",
    "bins = [-41, -5, 5, 41]\n",
    "names = ['1', '2', '3']\n",
    "\n",
    "multi_df = df.loc[:]\n",
    "multi_df['Category'] = pd.cut(multi_df['Bias'], bins, labels=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfVectorizer(max_features = 800)\n",
    "tfidf = tfidf_transformer.fit_transform(multi_df['cleaned_body'])\n",
    "\n",
    "X = pd.DataFrame(tfidf.toarray(), columns=tfidf_transformer.get_feature_names())\n",
    "y = multi_df['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = X.columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(scaled, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.5775656324582339\n"
     ]
    }
   ],
   "source": [
    "# Defining Model\n",
    "mnb = MultinomialNB()\n",
    "# Training Model\n",
    "mnb.fit(X_train, y_train)\n",
    "# Making Predictions\n",
    "y_pred = mnb.predict(X_test)\n",
    "# Evaluating\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score is:  0.7642936349523176\n"
     ]
    }
   ],
   "source": [
    "y_probs = mnb.predict_proba(X_test)\n",
    "roc_auc = roc_auc_score(y_test, y_probs, average=\"macro\", multi_class=\"ovo\")\n",
    "print('ROC Score is: ', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.60381861575179\n"
     ]
    }
   ],
   "source": [
    "# Defining Model\n",
    "regressor = LogisticRegression()\n",
    "# Training Model\n",
    "regressor.fit(X_train, y_train)\n",
    "# Making Predictions\n",
    "y_pred2 = regressor.predict(X_test)\n",
    "# Evaluating\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score is:  0.7748667274504489\n"
     ]
    }
   ],
   "source": [
    "y_probs = regressor.predict_proba(X_test)\n",
    "roc_auc = roc_auc_score(y_test, y_probs, average=\"macro\", multi_class=\"ovo\")\n",
    "print('ROC Score is: ', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third model - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6181384248210023\n"
     ]
    }
   ],
   "source": [
    "# Defining Model\n",
    "clf = SVC(probability=True)\n",
    "# Training Model\n",
    "clf.fit(X_train, y_train)\n",
    "# Making Predictions\n",
    "y_pred3 = clf.predict(X_test)\n",
    "# Evaluating\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score is:  0.8008702074588819\n"
     ]
    }
   ],
   "source": [
    "y_probs = clf.predict_proba(X_test)\n",
    "roc_auc = roc_auc_score(y_test, y_probs, average=\"macro\", multi_class=\"ovo\")\n",
    "print('ROC Score is: ', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'pred1': y_pred,\n",
    "                        'pred2': y_pred2,\n",
    "                        'pred3': y_pred3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pred1 pred2 pred3 final\n",
       "0     2     2     2     2\n",
       "1     1     3     3     3\n",
       "2     1     1     1     1\n",
       "3     2     2     2     2\n",
       "4     2     2     2     2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['final'] = results.mode(axis=1)[0]\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6229116945107399\n"
     ]
    }
   ],
   "source": [
    "final_pred = results['final']\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.62      0.57       162\n",
      "           2       0.62      0.66      0.64       167\n",
      "           3       0.59      0.36      0.44        90\n",
      "\n",
      "    accuracy                           0.58       419\n",
      "   macro avg       0.58      0.54      0.55       419\n",
      "weighted avg       0.58      0.58      0.57       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.65      0.62       162\n",
      "           2       0.64      0.67      0.65       167\n",
      "           3       0.56      0.39      0.46        90\n",
      "\n",
      "    accuracy                           0.60       419\n",
      "   macro avg       0.59      0.57      0.58       419\n",
      "weighted avg       0.60      0.60      0.60       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.70      0.62       162\n",
      "           2       0.66      0.73      0.70       167\n",
      "           3       0.71      0.27      0.39        90\n",
      "\n",
      "    accuracy                           0.62       419\n",
      "   macro avg       0.64      0.56      0.57       419\n",
      "weighted avg       0.63      0.62      0.60       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.70      0.63       162\n",
      "           2       0.67      0.70      0.68       167\n",
      "           3       0.66      0.34      0.45        90\n",
      "\n",
      "    accuracy                           0.62       419\n",
      "   macro avg       0.63      0.58      0.59       419\n",
      "weighted avg       0.63      0.62      0.61       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, final_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using VotingClassifier sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('svm', clf), \n",
    "              ('naivebayes', mnb), \n",
    "              ('logistic', regressor)]\n",
    "\n",
    "ensemble = VotingClassifier(estimators, voting='soft')\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "results = cross_val_score(ensemble, X, y, cv=kfold, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5773134328358209"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.630071599045346\n"
     ]
    }
   ],
   "source": [
    "estimators = [('svm', clf), \n",
    "              ('naivebayes', mnb), \n",
    "              ('logistic', regressor)]\n",
    "\n",
    "# Defining Model\n",
    "ensemble = VotingClassifier(estimators, voting='soft')\n",
    "# Training Model\n",
    "ensemble = ensemble.fit(X_train, y_train)\n",
    "# Making Predictions\n",
    "y_pred4 = ensemble.predict(X_test)\n",
    "# Evaluating\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score is:  0.7954219818251015\n"
     ]
    }
   ],
   "source": [
    "y_probs = ensemble.predict_proba(X_test)\n",
    "roc_auc = roc_auc_score(y_test, y_probs, average=\"macro\", multi_class=\"ovo\")\n",
    "print('ROC Score is: ', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Different Data Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Header and number of links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Url</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Header</th>\n",
       "      <th>Body</th>\n",
       "      <th>n_links</th>\n",
       "      <th>Source</th>\n",
       "      <th>Bias</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://abcnews.go.com/Politics/abortion-right...</td>\n",
       "      <td>Devin Dwyer</td>\n",
       "      <td>Wed, 17 Apr 2019 10:14:00 GMT</td>\n",
       "      <td>Abortion rights group asks Supreme Court to st...</td>\n",
       "      <td>Abortion rights advocates have asked the U.S. ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>1.67</td>\n",
       "      <td>49.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://abcnews.go.com/Politics/appeals-court-...</td>\n",
       "      <td>Ali Dukakis</td>\n",
       "      <td>Tue, 26 Feb 2019 09:05:00 GMT</td>\n",
       "      <td>Appeals court says special counsel Robert Muel...</td>\n",
       "      <td>A federal appeals court rejected the most dire...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>0.67</td>\n",
       "      <td>51.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://abcnews.go.com/Politics/attorney-gener...</td>\n",
       "      <td>Luke Barr</td>\n",
       "      <td>Wed, 17 Apr 2019 14:02:00 GMT</td>\n",
       "      <td>Attorney general orders some asylum seekers to...</td>\n",
       "      <td>As part of the Trump administration's effort t...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>43.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://abcnews.go.com/Politics/donald-trump-t...</td>\n",
       "      <td>Meridith McGraw</td>\n",
       "      <td>Tue, 19 Mar 2019 12:44:00 GMT</td>\n",
       "      <td>Donald Trump and 'the Trump of the Tropics,' B...</td>\n",
       "      <td>President Donald Trump and \"the Trump of the T...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>52.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://abcnews.go.com/Politics/electoral-coll...</td>\n",
       "      <td>Matthew Dowd</td>\n",
       "      <td>Tue, 19 Mar 2019 21:39:00 GMT</td>\n",
       "      <td>The Electoral College limits the campaign play...</td>\n",
       "      <td>U.S Senator Elizabeth Warren, who is competing...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ABC</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Url           Author  \\\n",
       "0  https://abcnews.go.com/Politics/abortion-right...      Devin Dwyer   \n",
       "1  https://abcnews.go.com/Politics/appeals-court-...      Ali Dukakis   \n",
       "2  https://abcnews.go.com/Politics/attorney-gener...        Luke Barr   \n",
       "3  https://abcnews.go.com/Politics/donald-trump-t...  Meridith McGraw   \n",
       "4  https://abcnews.go.com/Politics/electoral-coll...     Matthew Dowd   \n",
       "\n",
       "                            Date  \\\n",
       "0  Wed, 17 Apr 2019 10:14:00 GMT   \n",
       "1  Tue, 26 Feb 2019 09:05:00 GMT   \n",
       "2  Wed, 17 Apr 2019 14:02:00 GMT   \n",
       "3  Tue, 19 Mar 2019 12:44:00 GMT   \n",
       "4  Tue, 19 Mar 2019 21:39:00 GMT   \n",
       "\n",
       "                                              Header  \\\n",
       "0  Abortion rights group asks Supreme Court to st...   \n",
       "1  Appeals court says special counsel Robert Muel...   \n",
       "2  Attorney general orders some asylum seekers to...   \n",
       "3  Donald Trump and 'the Trump of the Tropics,' B...   \n",
       "4  The Electoral College limits the campaign play...   \n",
       "\n",
       "                                                Body  n_links Source   Bias  \\\n",
       "0  Abortion rights advocates have asked the U.S. ...      3.0    ABC   1.67   \n",
       "1  A federal appeals court rejected the most dire...      2.0    ABC   0.67   \n",
       "2  As part of the Trump administration's effort t...      6.0    ABC  -2.75   \n",
       "3  President Donald Trump and \"the Trump of the T...     10.0    ABC  -4.33   \n",
       "4  U.S Senator Elizabeth Warren, who is competing...      5.0    ABC -10.00   \n",
       "\n",
       "   Quality  \n",
       "0    49.00  \n",
       "1    51.67  \n",
       "2    43.50  \n",
       "3    52.67  \n",
       "4    32.00  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_data = pd.read_csv('../data/final_data.csv')\n",
    "df_total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.5107398568019093\n"
     ]
    }
   ],
   "source": [
    "tfidf = tfidf_transformer.fit_transform(df_total_data['Header'])\n",
    "X = pd.DataFrame(tfidf.toarray(), columns=tfidf_transformer.get_feature_names())\n",
    "\n",
    "for col in X.columns:\n",
    "    if col.isalpha() == False:\n",
    "        X = X.drop(col, axis=1)\n",
    "\n",
    "X.append(df_total_data['n_links'])\n",
    "\n",
    "#X[X.name.isalpha()]\n",
    "#X = X.drop(name for name in X if name.isalpha())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred5 = clf.predict(X_test)\n",
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score is:  0.6855527364987314\n"
     ]
    }
   ],
   "source": [
    "y_probs = clf.predict_proba(X_test)\n",
    "roc_auc = roc_auc_score(y_test, y_probs, average=\"macro\", multi_class=\"ovo\")\n",
    "print('ROC Score is: ', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiclass\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1384    2\n",
       "230     1\n",
       "1039    2\n",
       "443     1\n",
       "1665    3\n",
       "       ..\n",
       "902     1\n",
       "1074    2\n",
       "1024    3\n",
       "363     1\n",
       "10      1\n",
       "Name: Category, Length: 1256, dtype: category\n",
       "Categories (3, object): [1 < 2 < 3]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[20.  5.  0. ...  5.  2. 19.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-df367475a21f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy Score: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/practice/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    146\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[1;32m    147\u001b[0m                          \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/practice/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda2/envs/practice/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[20.  5.  0. ...  5.  2. 19.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred6 = clf.predict(X_test)\n",
    "print (\"Accuracy Score: \", accuracy_score(y_test, y_pred6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
