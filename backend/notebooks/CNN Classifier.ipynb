{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\quort\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\quort\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\quort\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip install -q tensorflow-hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "print(\"Version: \", tf.__version__)\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Model\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Loading\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "os.chdir(\"../\")\n",
    "from lib.utils import load_data\n",
    "os.chdir(\"notebooks/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Bias</th>\n",
       "      <th>cleaned_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Abortion rights advocates have asked the U.S. ...</td>\n",
       "      <td>1.67</td>\n",
       "      <td>abortion right advocate asked u supreme court ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A federal appeals court rejected the most dire...</td>\n",
       "      <td>0.67</td>\n",
       "      <td>federal appeal court rejected direct constitut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>As part of the Trump administration's effort t...</td>\n",
       "      <td>-2.75</td>\n",
       "      <td>part trump administration effort slow migrant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>President Donald Trump and \"the Trump of the T...</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>president donald trump trump tropic brazilian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>U.S Senator Elizabeth Warren, who is competing...</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>u senator elizabeth warren competing democrati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body   Bias  \\\n",
       "0  Abortion rights advocates have asked the U.S. ...   1.67   \n",
       "1  A federal appeals court rejected the most dire...   0.67   \n",
       "2  As part of the Trump administration's effort t...  -2.75   \n",
       "3  President Donald Trump and \"the Trump of the T...  -4.33   \n",
       "4  U.S Senator Elizabeth Warren, who is competing... -10.00   \n",
       "\n",
       "                                        cleaned_body  \n",
       "0  abortion right advocate asked u supreme court ...  \n",
       "1  federal appeal court rejected direct constitut...  \n",
       "2  part trump administration effort slow migrant ...  \n",
       "3  president donald trump trump tropic brazilian ...  \n",
       "4  u senator elizabeth warren competing democrati...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Bias'] <= 0, 'Bias'] = 0\n",
    "df.loc[df['Bias'] > 0, 'Bias'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, testval_set = train_test_split(df)\n",
    "val_set, test_set = train_test_split(testval_set, train_size=0.5)\n",
    "\n",
    "X_train = train_set['cleaned_body']\n",
    "X_val = val_set['cleaned_body']\n",
    "X_test = test_set['cleaned_body']\n",
    "\n",
    "y_train = train_set['Bias'].values\n",
    "y_val = val_set['Bias'].values\n",
    "y_test = test_set['Bias'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
    "sequences_val = tokenizer.texts_to_sequences(X_val)\n",
    "sequences_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (1256, 2000)\n",
      "Validation shape:  (209, 2000)\n",
      "Testing shape:  (210, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Padding sequences\n",
    "#X_train_pad = pad_sequences(sequences_train)\n",
    "\n",
    "#MAX_LEN = X_train_pad.shape[1]\n",
    "MAX_LEN = 2000\n",
    "\n",
    "X_train_pad = pad_sequences(sequences_train, maxlen=MAX_LEN)\n",
    "X_val_pad = pad_sequences(sequences_val, maxlen=MAX_LEN)\n",
    "X_test_pad = pad_sequences(sequences_test, maxlen=MAX_LEN)\n",
    "\n",
    "print('Training shape: ', X_train_pad.shape)\n",
    "print('Validation shape: ', X_val_pad.shape)\n",
    "print('Testing shape: ', X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_dataset(mat, batch_size):\n",
    "    \"\"\"\n",
    "    trims dataset to a size that's divisible by the batch size\n",
    "    \"\"\"\n",
    "\n",
    "    no_of_rows_drop = mat.shape[0] % batch_size\n",
    "    if(no_of_rows_drop > 0):\n",
    "        return mat[:-no_of_rows_drop]\n",
    "    else:\n",
    "        return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1256, 20), dtype=float32, numpy=\n",
       "array([[-6.7498541e-01, -2.9683700e+00,  9.1933184e+00, ...,\n",
       "        -3.7393546e+00, -3.6545901e+00,  2.2885122e-03],\n",
       "       [ 4.5606480e+00,  3.1452041e+00,  2.3387189e+00, ...,\n",
       "        -5.3740139e+00, -4.0858994e+00, -4.7504001e+00],\n",
       "       [ 3.3300530e-02, -2.1278386e+00,  3.6390228e+00, ...,\n",
       "        -5.1505122e+00, -9.9419880e-01, -1.3399523e+00],\n",
       "       ...,\n",
       "       [ 1.3918315e+00, -2.3847456e+00,  1.4652982e+01, ...,\n",
       "        -8.8711891e+00, -6.9092298e+00,  1.6106667e-01],\n",
       "       [ 1.7348050e+00, -2.4183793e+00,  4.2662964e+00, ...,\n",
       "        -2.1665649e+01,  4.1643882e+00, -8.3186274e+00],\n",
       "       [ 5.4037565e-01, -3.6619914e+00,  4.0706768e+00, ...,\n",
       "        -4.8490100e+00, -3.5005054e+00, -5.4608405e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "hub_layer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_4 (KerasLayer)   (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 400,373\n",
      "Trainable params: 400,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.shuffle(len(df)).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1256 steps\n",
      "Epoch 1/5\n",
      "1256/1256 [==============================] - 6s 5ms/step - loss: 0.6725 - accuracy: 0.6760\n",
      "Epoch 2/5\n",
      "1256/1256 [==============================] - 6s 5ms/step - loss: 0.5511 - accuracy: 0.7014\n",
      "Epoch 3/5\n",
      " 907/1256 [====================>.........] - ETA: 1s - loss: 0.4504 - accuracy: 0.7508"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "y_pred = [i for sublist in y_pred for i in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
